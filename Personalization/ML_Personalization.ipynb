{
 "cells": [
  {
   "attachments": {
    "AlbertsonsImgae.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOEAAADhCAMAAAAJbSJIAAAAwFBMVEX///8AU6AAouIAR5sARZoAnuG/z+O2yN8AneEAoOEAUZ8Am+AAT54AUJ8ASpwATZ16xu0AQpl8msQrY6js8/nr+P31/P7g8/tvw+z2/f5/yu7u8/kAmN/Y7/pVuelJteiP0PCr3PTK2OnJ6fgrquShttXO2+rj6/Sl2fOswduSrdA1a6xchLkAPZdNerSq3PS74vYYXKVrkMAAN5SIpszZ5PA0ruZCdLFmirxUf7ZylMKZs9OZ2fOG0fBVt+nC6vn2jAUlAAAR/ElEQVR4nO1dZ1uzPBQOq4xSkLbQZfegy1p8OtT66v//V28WdEGDirZeV+4PiiXQ3OTkrJwgABwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcqZBTEzAJUb52F7+HnSNdxr9XANy2e+1+fhmqLVyGNfdArZVvX7ujX8VIKFwmaM+gjNY1Uateu6tfgx+YlwkWhDUAY00UxfzbtTv7FXgzhowacg+Avq6LiOLy2t39AhYWYxI6EwAqIiYo6krz2v39NJ4kFsEVHOcNIQgpDv6aQp06DILWC2zVUsQQSrt27T5/CiqLoD2Dre72BMU/plBHrDloBj4Ab5p4CK1z7W6nhx8YlwkahREAS0U/Yijq3Wt3PC3KLDshWCpUo/oJQahW+9fuejp4c5aMSlPojQ5OCSKFWrl251OhKLMIQne71lbOCEKKm7+gUKcsgtaLB0BViyEItU3r2t1nYyIxtAx2tzv5WILQfetcmwALPZupRqG73U0iKIr3N+6h+gYjYBIeoLv9ES+iVFBv2kP1ApadeIDudvPMThxpG/GWFeqWRRC525UYO3FEceNdm0cimPGENYetqsmTkMrpzSpUZjyB3W3gbi6PIaRYvzaVeKgsQ4jdbcAWUxhKja/MJRZsO2GMaNP+RVUj3qiHysw7YXeb4vGSucAUb89DbTDjCeRuR+gwKd6aQk0RT7weXZDglx5MxRtTqEWmnVgcX1D7YwqVGU/YpQZt+kJ/uyxtI+Yfr0XnHBM5jbuNsfq3okdNluEX729GofYsFkGU3cZYO/vjJYuirt+IQvUFBkGc3SYomYIZCexfUaheKY27TYAV0l6r/hGFylyfkJ7DpjniuEqh6a+14pI1h7gFhcrMOxF3G6EckPC4QP3TVE741T3UISueMCM6IPIKcBCF0RRZHqr+cR1iIVS2nQjdbTDcj7Y0DD9csp3wq2Y1RiZLje7d7bWxb2sI0cCOmTZjc8V1N3Y8ceBuH3mu9kv0+d0NK1TmOvahu30SH8uRiQRMharcXYMdwvwT7rY3Ox5uw46MeY0Z8l+rkCGFnWhEjc9SHAfym8IJv4pC3bFGEBeThFicCrQh7E8ynXBduYKHqrJcGcPq7Vuvz5WuM9qf7rKzGr/uoY6M9O42xPB8wKXdwfk6W6H+8rpbmWkn9u42wvxc69pPhw3YHuovK1S2nXg+bn++YGNuDxt47dvyUJ9ZWmbvbmM0YkoXCqWjJinSxL+47rZiu9vHhbHlmDbGMUPQZzrhv+ehTlgEDXt0fEU5bgxnJ7dNoVB/yUPtMeMJST29pnQ+Dw9cU4rEpe9ITn+nMmxdYNkJeXd20ZnBhy7d6qwVM6vxK5VhZWZaRi6eXzU9V03O2UADEFuCckSx8+MEU6Rl5jFXjc4Tjk5MlX5cGdEJxR+vDHtiETx0tw9wtv5tnioajPNSsBPo+g8r1BhpO+n4Pi1zhMnphfIktl2f6YSLP6pQJ0x32+7FX3kaHxaChK9IkSb+QYXKXOYV5Bj1QaAeD6IUP4QQVaa2+TmF6gtMd3sKehFGa79xMCdfDmeidaCOGuWGv0eDve72Y5VhNaadkJ5A2XTkEJJllBZFlbJcHxj9KCfcUIuLQLCtCNLsigqVucxrb9E4H8EwLcd6JnNzd5AvJTI6ehUcC8bGxgGENGli5UfW3VK4295xVjRkaT+84CGLHBsLh1brFyfmmdnwzAc7TfwDWY3hA4OgYSEaMQxRt2WU5PZpYWYhQIK7eogVesQwhROevULtsQgKUg618+NPGs7cixY5UEu/FJ+powkqphOeeWUYexVUJksRcbEuhrVtUDmViijNk6CWDerqsJ3wjLMaL0xvNIwUEssTLejO+Y4BY/sGGBWS7I5Ns+Qee90t0zRxTKrspGNRdruY+CzQPqCVhJyCC+sdkTPXZ07FLD3UdDtECHrJow3H2UO23rtQhupEbi0zwahnuPWU6W9b+xUYr5T4NAypB4b/Rmggk2DvE3AeyyqKWmZW0YvJQRx33TrIy1zI9psl0HgC6wu+n5zb36jDclD1zBxU9j6tw5KuRvIgIoXrXfKNjpKQLrveJiuGTCE9Kjs8DwX3QNZulBygHC11AMBMEuezEtOYlPzJ0BwnDy+UezvqpSyBdJzhYYppZmnwLSNoMgrHiQtvlkjCXHjJvoO1Pf5edllYVhNxxrIVpZOlr0Yp2SgOEwXCmp3cpvJr9mLGGENzceoGe9uk9WEj0bTKi9MUlsdUppuMGMakc48ZnmWvUazFmrwn93BisqwsTZMZQ1YGMY4hGG0dZrFNCMN2ZrmYezAZZiWlLK/U3MZepr7YsmXbZgGGjLFcUURvmLYlF+Zq3CI2W0qz0jQXLBjp6ammCeFPis+L7awUCLYkHd3EsCXLsmwjKG3nKzU+xcrWNJlZi9Nc57mQxaa5w6sb5bK/7u0W9n5m2vbLcLRer32/fKEC4YNlLTKz+EynRo6bRGfobel8NqxFQt74GGPGGOri92gdICE1ESFmoSwO3it5UtaU3RahxdA0SobltclhLUbh1FYn3kdCMVRiuvsYNWb0lGHCzWfo/XRiCnCOQ045gpc2CxMhzTQZtbucLLUX7Ftg+E7qpoCRqcl6rwJj/2vyiswJXv+N2I0wWH63lvGWmvVlhoUg5XvXRiV2GwyPsXqRfRW/+iDLeNFlv/JyiIe0wpd2FrbulUvI/8A2hdFoRFbNciegL9FLOYgptW6/TnF3DvTpDe364uDg4EiJSr3aarWqneWBJqx1Wy1a2lL7a2+TO8fdvY6g3EeuYOVOz9PldLeu529ks+fX0Qz9CxpzVtp59CoyHf1Vh4efXiO5uSfihutASgf/TVdoIcP+QBE/HWzDB5Td2l82C/qocgBz1EkNKy2w05teHh98bgyXoq5lVbPtvj0+ZqEFYLStU0+YyNebQhiCMf70U+/m7MDHk1lBzONy+ZaBB1eBwVirVkesaDnSUqMMASaOGLqV/bN0m8vlst+kH3huZX/ObaEZTOvuYbvueDzuh9Oy0h93OuPoQuBVmuS4+djdT10XtvqvM16iTx4//utnUCE11vCUQwEbTVHSIskmjVOVplsf6AOa3KtUB7qmaYo+qEPrsmxtBqI4aAK3U4UYkNEfvL+7Lm2naWLVxdeJGgY8i3rdr27gox1UwLKtKJpOBdu9G6BLNEUR2004hu5jBhLfht8D558iRvXyTTSGuDIJL/LprYEGBZnoD3cAR0lX0A9U9dLOI0OTX/ZhE4QwQr9/22hoNElDOL8r6B70Qh1V54kaaq3XWxr+DpLgdg9aKQP4AB+X39c10FYoVRCSwTOoQthWwoQY1Ty4E/itpPp4iZprY2pp4DPQxYNiLl3X8Ojr9WW3reOdW1hB69VOHSk1lKMYk5x3+IpMMtlx/am+WfaRbsgqnQgnIJ43eMWS1JK70XhShqQbyGrg0kJkVRA1NPakJlYnTShJfdDqIoY4m+Rq6Dd+pTCeBF10c/QipfbhvWlU3w7nfV/LbGUG5xPQrMYlLvo7/kwPGVbxN9b7ZESq1DvQ0JZI9BFUmuSFQrrYaXpQ55B2ULywjsIMl3nx/oPUsuE8fSWUhzvSdkyKaomEEM1Wwcohq4TpUqGzr7mfiB459AhDdIATR7rokUw13hHZJoP5iLVSuGsJPxH88ElfYSff7+/rVLhxK1xDq4s1UMct3mhTUpBIntCmAqr5+6w2JSI51DUoK8SRwaZszxA9Z+QHkDKt/Aedhi5lCEcV5z2jHT3VSGuQbKEi1j+6ffo19DngQ+hFkGmxDIu/sZsQzor64zirrbMuuWWkI7BoeNFwYoZIcnF34JCR7lXCCRkyDF9TsmdIa9ahWtxEXVewbavT4RyHDCtEDNAkDUulFL09zsi7hV+jV/tiXlPIjMcS5upHDJEvR8zlHe1pvd/B8+y+S+U3XMwkDNH088RwfRAaC5c+GWxSiaB39gypmKKnVNGiV4AreicThlCY4ON0u536XSuaDntdiudh2wtJt8A7FSNs/VpLmtqNUvB7hqDS0iJL0KYqCzPEHpNep8oHDesd9YPhYXOw55jJNnZo2/e74gbhXKmcM8Tb6uFQ0Ymiie3qu1J34xnSEe1XReK6QztDRBNrx75C9HI38hNJApyMsDfeKJQkUkffBjKGUbEqec5Vujwb2UNiQbAG3IQUuhXopYgadOy6RwxbEcM+GhG328YTS+ngASPNjhliA4IZ4rOQk9fvvBPDmsXyk6gfbE8da3QiEq9tQL02ElNtyBgSB51E/wM93yX2MGK4Ca1FLU8aecQmdAitwTnDDu0GeaStDSHVH+jZMMQrzVFg0CcSWKHGH83IDbWHkQXfW27UHOoJrGT1cHMktfgeHJZQv26we1ch0loJGUKBxZqGSFCVfHPfU5QBuRNx375vEav64W5/0guo5bphfEgeLtJ3S/rAm5HTUmvpyL2sH3jsoRXUP5DgQTPhUZ8p369FXlGkdMizwaNPwjXIGuqw9z66qqWLWZSbILt3sLmB1NLp+hsJh2F3muQTsYU3R+KNZXhrvdJ+68AuQ1+SZkDCF3aGnvoYhSp6Xmy3BmT+0jfVKJvqBt9Kd2s0r4AmiUtVS2dArnrHPcjgtcoVlGTLR2Urok6g0d/33Xp4iEMk7O9UBjBewvENvrKKY6BoV10/r5BLvWoeB0ekLdI6rTzxzfHP/CPo0gwf9q/b5IvucUilk6vus/BLH1vtwSZKOXQ3GAMCcVB1m+QP2KdB++6RiHOtC0NbGKBuqujCPmwBA91B+LibVXTBBg7pGA5fHgFHyhAdMU+htOGltfoG3Zlc6bbQN7XH8CpRQ030TeeW3hrtJdgtr9Lc5ywASoU0+/2PfvOymXObzebfT0JzZAavl/Sf024Due/+3zZ/xvjHadeGHKSsP0oaweRy5s+gYEmoEDFtuWkcjKT6yIKUtlopFsx3fKTqnFQqTtTh3Cx94x7CPEg4df5+jc+AUc+WrnPSFOSeF689P8fat5EMawWmCX0xSpdqP3+DobQDU8c2LWcy+rpEGDN1kbRjsfQdZZMBQ3MGyg6aQ4VgjcbQkiT0jgzDtsyCJNtoB62E6q3gB4Yl4320BmqDrrXh5JVkC3/0D39ikqvhb9myb4ShpIbbhMwXQzDtaS5XtAxjNp9uZ2quKMmvOfUFNlg8T4NVboL+QYa0Qidg119Wz8Ekt7Lg4XyFdu5IWzU3tAqCBX9Pn2+DoWGvo7ugdwgDVQjW68Cer8FktMqBldpblcHWNFceGPUmHggK1npiL9B7Q7c9kBtNVTCUzMUaDC1IvbG11YZhPXtzYdWQboOh4YPXqOpPXjegLC7gqMIfa8eSfTB8kLdolB+GYPrgIGYzSMnJASikASgLkoSuseGHlrkFq3+yBab/VF+SpYl9GwwLPljRu9hmAKA+NYJyw7K3SDnKOTAzDQG9NANq3IUtFIAvF54CGcp2YBgBPtED+MVgQws2UXe7Hcg9TIG/CqiFvDZDwRqBCdkiZL8GM4Atht9Am0UhcVn1SsYBQ8NueJYdDEeqH8dQBcXtYrEtFYxhA3ir25BSVLZeJq/OsnoBHEMZjaFvxTMUCt7agadnTuwYDsGrbJpmwRCkoNiguwavztAIGqAIKRrSiyfIZV8yILmhdMjQQO/+xAzhdNs5r6DoIIY2YghP9LwCZijZz2AEjQQkvSrZzgvdJHF1hoK9aIBVSSg9r0FgPYGVKeT8UsF+Qq/zgSK8taHFHFnI81EDIQfl9xn0tkUfPG+tLVgLhcIazlV7DnJQhlXQe3rerZzhBG2ufrmNMYTSGaxG615vMlvNDGney+WGgW0/5VRo6HY5dVKaoUNTwq+2UUu2YO98f7dYrxcLeGIiTHOqWnqGh9OCYa7WDX9oWNDPVXN0w9kNMIQC6kjQTTGQN2LL6Aj9dqBDYzmOZBRkx7GQlG6h+UC7xiUZujmybJsSOmHJsA1qbiHXxpGR34P8IPlWfJq0IJrmC+AMb4Yh1J5F1gsZY/G96CmTCDhVN4WJOsntvjKI34uAQTZZjBSAwZNkfYWgKaXa6ZcIfxG7f+SGUEq7HykR69MNJLeF3ncmIQcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwfHzeF/Pt+rCmMchwMAAAAASUVORK5CYII="
    }
   },
   "cell_type": "markdown",
   "id": "773b85f4",
   "metadata": {},
   "source": [
    "![AlbertsonsImgae.png](attachment:AlbertsonsImgae.png)\n",
    "\n",
    "# Machine Learning - Personalization for business in reatil industry\n",
    "\n",
    "### Introduction\n",
    "This case study is about identifying the customers dietary preferences based on customer's shopping history\n",
    "\n",
    "### Objective - Identifying the Customer's Dietary Prefernce\n",
    "\n",
    "### Business Problem\n",
    "\n",
    "Identifying customer's dietary preferences is crucial in the retail industry, particularly in food and beverages, for several reasons \n",
    "\n",
    "1. **Presonalization:** Understanding dietary preferences allows reatilers to provide personalized recommendations and offers to customers. This enhances the shopping experience and the likelihood of making a sale\n",
    "2. **Customer Satisfaction:** Catering to dieatry preferences ensures that customers can find products that align with their needs and values.Satisfied customers are more likely to return and become loyal shoppers.\n",
    "3. **Market Segmentation:** By identifying the different dietary segments(e.g. vegetarian, vegan, paleo, gluten-free) retailers can tailor their product offerings and marketing startegies to target specific customer groups effectivel.\n",
    "4. **Marketing Efficiency:** Retailers can create targeted marketing campaigns that resonate with specific dietary segment, leading to higher return on marketing investment.\n",
    "5. **Data-Driven Decision Making:** Gathering data on dietary preferences enables reatilers to make data-driven decisions aboutproduct offerings, inventory management, and marketing strategies, leading to more informed choices.\n",
    "\n",
    "\n",
    "### Type of Problem - Classification\n",
    "\n",
    "We can use previous purchase data to identify the customers dietary preference\n",
    "\n",
    "### Classification \n",
    "\n",
    "A classification algorithm is a supervised learning technique that uses data training to determine data into different classes. Classification predictive modeling is trained using data or observations, and new observations are categorized into classes or groups.\n",
    "1. **Logistic Regression:** Statistical model (also known as logit model) is often used for classification and predictive analytics. Logistic regression estimates the probability of an event occurring, such as voted or didn’t vote, based on a given dataset of independent variables.We will use**Multinomial logistic regression:** In this type of logistic regression model, the dependent variable has three or more possible outcomes; however, these values have no specified order.  For example, movie studios want to predict what genre of film a moviegoer is likely to see to market films more effectively. A multinomial logistic regression model can help indentify a customers dietary preference.\n",
    "\n",
    "2. **RandomForestClassifier:** A random forest is a meta estimator that fits a number of decision tree classifiers on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting. The sub-sample size is controlled with the max_samples parameter if bootstrap=True (default), otherwise the whole dataset is used to build each tree.\n",
    "-  Random forests are a popular supervised machine learning algorithm. \n",
    "    *  Random forests are for supervised machine learning, where there is a labeled target variable.\n",
    "    *  Random forests can be used for solving regression (numeric target variable) and classification (categorical target variable) problems. \n",
    "    *  Random forests are an ensemble method, meaning they combine predictions from other models.\n",
    "    *  Each of the smaller models in the random forest ensemble is a decision tree.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef18ebf",
   "metadata": {},
   "source": [
    "# Importing the necessay libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c012d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --trusted-host pypi.org --trusted-host files.pythonhosted.org -r ./../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7492c549",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6d3f33",
   "metadata": {},
   "source": [
    "# Reading the features csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f1bce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"features.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd5ec3c",
   "metadata": {},
   "source": [
    "### Shape attribute in Pandas enables us to obtain the shape of a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc088eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b3a419",
   "metadata": {},
   "source": [
    "### Pandas head function returns the first 10 rows for the object based on position. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22965d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7756a33",
   "metadata": {},
   "source": [
    "### Pandas column is part of a two-dimensional data structure in which one of the attributes is a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8f5350",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba33475",
   "metadata": {},
   "source": [
    "### Columns Description \n",
    "*  **customer_id:** unique customer identifier\n",
    "*  **dp:** Dietary preference\n",
    "*  **num_txn:** Number of transactions done by the household \n",
    "*  **basket_pct_MILK_FREE:** Percentage of milk free transactions\n",
    "*  **basket_pct_EGG_FREE:** Percentage of egg free transactions\n",
    "*  **basket_pct_GLUTEN_FREE:** Percentage of gluten free transactions\n",
    "*  **basket_pct_VEGETARIAN:** Percentage of vegetarian transactions\n",
    "*  **basket_pct_VEGAN:** Percentage of vegan transactions\n",
    "*  **basket_pct_KETO:** Percentage of keto transactions\n",
    "*  **basket_pct_PALEO:** Percentage of paleo transactions\n",
    "*  **basket_pct_SHELLFISH_FREE:** Percentage of shellfish free transactions\n",
    "*  **basket_pct_SOY_FREE:** Percentage of soy free transactions\n",
    "*  **basket_pct_LACTOSE_FREE:** Percentage of lactose free transactions\n",
    "*  **basket_pct_PEANUT_FREE:** Percentage of peanut free transactions\n",
    "*  **basket_pct_PESCATARIAN:** Percentage of pescatarian transactions\n",
    "*  **basket_pct_TREE_NUT_FREE:** Percentage of tree nut free transactions\n",
    "*  **basket_pct_LOW_CARB:** Percentage of low carb transactions\n",
    "*  **basket_pct_WHEAT_FREE:** Percentage of wheat free transactions\n",
    "*  **basket_pct_NO_DIET_PREFERENCES:** Percentage of No Dieatry Preferences Transactions\n",
    "*  **basket_pct_NO_DIET_RESTRICTIONS:** Percentage of No Dietary Restrictions transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711ae57a",
   "metadata": {},
   "source": [
    "### The Pandas describe() method returns description of the data in the DataFrame.\n",
    "\n",
    "    If the DataFrame contains numerical data, the description contains these information for each column:\n",
    "\n",
    "    count - The number of not-empty values.\n",
    "    mean - The average (mean) value.\n",
    "    std - The standard deviation.\n",
    "    min - the minimum value.\n",
    "    25% - The 25% percentile*.\n",
    "    50% - The 50% percentile*.\n",
    "    75% - The 75% percentile*.\n",
    "    max - the maximum value.\n",
    "\n",
    "    *Percentile meaning: how many of the values are less than the given percentile. Read more about percentiles in our Machine Learning Percentile chapter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b696f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f08974",
   "metadata": {},
   "source": [
    "### No of unique value counts in the dp (dietary preference) column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360c5085",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"dp\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e9aa52",
   "metadata": {},
   "source": [
    "# List of features and model choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43496a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_feature = \"dp\"\n",
    "X_feature_list = list(set(df.columns) - set([Y_feature, \"household_id\"]))\n",
    "model_type = \"RF\" # RF or LR. two models were trained and compared"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f801626",
   "metadata": {},
   "source": [
    "### We choose the model_type  : either RandomForestClassifier or Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03fac70",
   "metadata": {},
   "source": [
    "## Cross-validation\n",
    "*  Cross-validation is a statistical method used to estimate the skill of machine learning models.\n",
    "\n",
    "*  It is commonly used in applied machine learning to compare and select a model for a given predictive modeling problem "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdcf6f9",
   "metadata": {},
   "source": [
    "## K-fold : Cross-Validation\n",
    "Cross-validation is a resampling procedure used to evaluate machine learning models on a limited data sample.\n",
    "\n",
    "The procedure has a single parameter called k that refers to the number of groups that a given data sample is to be split into. As such, the procedure is often called k-fold cross-validation. When a specific value for k is chosen, it may be used in place of k in the reference to the model, such as k=10 becoming 10-fold cross-validation.\n",
    "\n",
    "Cross-validation is primarily used in applied machine learning to estimate the skill of a machine learning model on unseen data. That is, to use a limited sample in order to estimate how the model is expected to perform in general when used to make predictions on data not used during the training of the model.\n",
    "\n",
    "It is a popular method because it is simple to understand and because it generally results in a less biased or less optimistic estimate of the model skill than other methods, such as a simple train/test split.\n",
    "\n",
    "The general procedure is as follows:\n",
    "\n",
    "* Shuffle the dataset randomly.\n",
    "* Split the dataset into k groups\n",
    "* For each unique group:\n",
    "    * Take the group as a hold out or test data set\n",
    "    * Take the remaining groups as a training data set\n",
    "    * Fit a model on the training set and evaluate it on the test set\n",
    "* Retain the evaluation score and discard the model\n",
    "* Summarize the skill of the model using the sample of model evaluation scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527979ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-fold\n",
    "X = df[X_feature_list].to_numpy(); y = df[Y_feature].to_numpy()\n",
    "\n",
    "strtfdKFold = StratifiedKFold(n_splits=10, shuffle=True, random_state = 42)\n",
    "kfolds = strtfdKFold.split(X, y)\n",
    "\n",
    "table = []\n",
    "for k, (train_rows, test_rows) in enumerate(kfolds):\n",
    "  if model_type == \"RF\":\n",
    "    X_train = X[train_rows]\n",
    "    X_test = X[test_rows]\n",
    "    model = RandomForestClassifier(n_estimators=100, max_depth=5, min_samples_leaf=10, random_state=42).fit(X_train, y[train_rows])    \n",
    "  elif model_type == \"LR\":\n",
    "    scaler = StandardScaler().fit(X[train_rows])\n",
    "    X_train = scaler.transform(X[train_rows])\n",
    "    X_test = scaler.transform(X[test_rows])\n",
    "    model = LogisticRegression(C = 0.8, random_state=42).fit(X_train, y[train_rows])\n",
    "    \n",
    "  y_hat = model.predict(X_train)\n",
    "  y_pred = model.predict(X_test)\n",
    "  train_precision, train_recall, train_fscore, _ = precision_recall_fscore_support(y[train_rows], y_hat, pos_label = 1, average='micro')\n",
    "  test_precision, test_recall, test_fscore, _ = precision_recall_fscore_support(y[test_rows], y_pred, pos_label = 1, average='micro')\n",
    "       \n",
    "  table.append([k, X_train.shape[0], 100. * train_precision, 100. * train_recall, 100. * train_fscore,\\\n",
    "                X_test.shape[0], 100. * test_precision, 100. * test_recall, 100. * test_fscore])\n",
    "Kfold_performance_df = pd.DataFrame(table, columns = ['k', 'train_L', 'train_precision', 'train_recall', 'train_fscore',\\\n",
    "                                                 'test_L', 'test_precision', 'test_recall', 'test_fscore'])\n",
    "Kfold_performance_df.round(decimals = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2d2fc0",
   "metadata": {},
   "source": [
    "### K-fold output parameters\n",
    "    * k: number folds\n",
    "    * train_L: numbers of records used for training\n",
    "    * train_precision: Precision of the train data\n",
    "    * train_recall: Recall of the train data\n",
    "    * train_fscore: F1 score of the train data \n",
    "    * test_L: numbers of records used for testing\n",
    "    * test_precision: Precision of the test data\n",
    "    * test_recall: Recall of the test data\n",
    "    * test_fscore: F1 score of the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8697135",
   "metadata": {},
   "source": [
    "**F1 score** is a machine learning evaluation metric that measures a model’s accuracy. It combines the precision and recall scores of a model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e401fe",
   "metadata": {},
   "source": [
    "<img src=\"Confusion_Matrix.png\" width=\"65%\"/>\n",
    "<img src=\"Precision_Recall.png\" width=\"65%\"/>\n",
    "<img src=\"F1_Score.png\" width=\"65%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42268a5e",
   "metadata": {},
   "source": [
    "**GridSearchCV** is the process of performing hyperparameter tuning in order to determine the optimal values for a given model. The performance of a model significantly depends on the value of hyperparameters. Note that there is no way to know in advance the best values for hyperparameters so ideally, we need to try all possible values to know the optimal values. Doing this manually could take a considerable amount of time and resources and thus we use GridSearchCV to automate the tuning of hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810df99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-fold + GridSearchCV\n",
    "X = df[X_feature_list].to_numpy(); y = df[Y_feature].to_numpy()\n",
    "\n",
    "strtfdKFold = StratifiedKFold(n_splits=10, shuffle=True, random_state = 42)\n",
    "kfolds = strtfdKFold.split(X, y)\n",
    "\n",
    "best_parameters = None\n",
    "table = []\n",
    "for k, (train_rows, test_rows) in enumerate(kfolds):\n",
    "  if isinstance(best_parameters, dict) == False:\n",
    "    print(\"capturing best hyper parameters\")\n",
    "    if model_type == \"RF\":\n",
    "      model = RandomForestClassifier(random_state=42)\n",
    "      parameters = {'n_estimators':[100, 200, 500], 'max_depth':[1, 5, 10], 'min_samples_leaf': [1, 5, 10]}\n",
    "      X_train = X[train_rows]\n",
    "      X_test = X[test_rows]\n",
    "    elif model_type == \"LR\":\n",
    "      model = LogisticRegression(random_state=42)\n",
    "      parameters = {'C':[0.5, 0.75, 1, 1.5, 2.0]}\n",
    "      scaler = StandardScaler().fit(X[train_rows])\n",
    "      X_train = scaler.transform(X[train_rows])\n",
    "      X_test = scaler.transform(X[test_rows])  \n",
    "    model_GS = GridSearchCV(model, parameters)\n",
    "    model_GS.fit(X_train, y[train_rows])\n",
    "    best_parameters = model_GS.best_params_\n",
    "\n",
    "  if model_type == \"RF\":\n",
    "    X_train = X[train_rows]\n",
    "    X_test = X[test_rows]\n",
    "    model = RandomForestClassifier(**best_parameters, random_state=42).fit(X_train, y[train_rows])    \n",
    "  elif model_type == \"LR\":\n",
    "    scaler = StandardScaler().fit(X[train_rows])\n",
    "    X_train = scaler.transform(X[train_rows])\n",
    "    X_test = scaler.transform(X[test_rows])\n",
    "    model = LogisticRegression(**best_parameters, random_state=42).fit(X_train, y[train_rows])\n",
    "    \n",
    "  y_hat = model.predict(X_train)\n",
    "  y_pred = model.predict(X_test)\n",
    "  train_precision, train_recall, train_fscore, _ = precision_recall_fscore_support(y[train_rows], y_hat, pos_label = 1, average='micro')\n",
    "  test_precision, test_recall, test_fscore, _ = precision_recall_fscore_support(y[test_rows], y_pred, pos_label = 1, average='micro')\n",
    "       \n",
    "  table.append([k, X_train.shape[0], 100. * train_precision, 100. * train_recall, 100. * train_fscore,\\\n",
    "                X_test.shape[0], 100. * test_precision, 100. * test_recall, 100. * test_fscore])\n",
    "Kfold_performance_df = pd.DataFrame(table, columns = ['k', 'train_L', 'train_precision', 'train_recall', 'train_fscore',\\\n",
    "                                                 'test_L', 'test_precision', 'test_recall', 'test_fscore'])\n",
    "Kfold_performance_df.round(decimals = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056ef8aa",
   "metadata": {},
   "source": [
    "### Print the best parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6715af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3665d618",
   "metadata": {},
   "source": [
    "### Creating a dataframe consisting of output results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b1ea48",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results_df = pd.DataFrame({'actual_dp': y[test_rows], 'predicted_dp': y_pred})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622a22c6",
   "metadata": {},
   "source": [
    "### Pandas groupby is used for grouping the data according to the categories and applying a function to the categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb667e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_results_df.groupby('actual_dp').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13b2bde",
   "metadata": {},
   "source": [
    "### Paleo is easier to detect (higher accuracy). The lowest accuracy is pescatarian & keto "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a252d53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results_df[test_results_df['actual_dp'] == test_results_df['predicted_dp']].groupby(['actual_dp']).size() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ecf689",
   "metadata": {},
   "source": [
    "### Getting the important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ca0b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_df = pd.DataFrame()\n",
    "if model_type == \"RF\":\n",
    "  feature_importance_df[\"feature\"] = X_feature_list\n",
    "  feature_importance_df[\"importance\"] = model.feature_importances_\n",
    "  feature_importance_df.sort_values(by=[\"importance\"], ascending = False, inplace = True)\n",
    "feature_importance_df.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ef5fe7-7ce5-41b7-ae67-2c2f22a1e55b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
